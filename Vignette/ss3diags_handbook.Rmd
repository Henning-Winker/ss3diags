---
title: "User guidelines for Advanced Model Diagnostics with ss3diags"
author: "Hennig Winker, Felipe Carvalho, Massimiliano Cardinale & Laurence Kell"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    keep_tex: false
vignette: >
  %\VignetteIndexEntry{ss3daigs Vignetted}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "  " ,fig.align = 'center', cache=FALSE)
```


# Getting started (UNDER CONSTRUCTION)

This vignette explains functions for applying advanced model diagnostics for Stock Synthesis model with the `ss3diags` R package for model. The `ss3diags` package builds on R package `r4ss` (Taylor et al. 2021), which is designed to support the use of the Stock Synthesis software (Methot and Wetzel, 2013).

## Installation

Both `ss3diags` and `r4ss` can be installed from gihtub using library(devtools):

```{r, eval=FALSE}
installed.packages("devtools")

devtools::install_github("JABBAmodel/r4ss")

devtools::install_github("JABBAmodel/ss3diags")
```


```{r}
library(r4ss)
library(ss3diags)
```

## Loading built-in example data

The package contains two examples of Stock Synthesis assessments as presented in [Carvalho, Winker et (2021)](https://www.sciencedirect.com/science/article/pii/S0165783621000874). 

### The Pacif hake (*Merluccius productus*) base case model

2020 Pacific hake/whiting Stock Synthesis assessment. Joint Technical Committee of the U.S. and Canada Pacific Hake/Whiting Agreement, National Marine Fisheries Service and Fisheries and Oceans Canada 
<br>
```{r}
data("pac.hke")
```
<br>
Individual list objects generated using R package [r4ss](https://github.com/r4ss/r4ss):
<br>

- `ss3phk`:  output from Stock Synthesis as read by `r4ss::SS_output()` 

<br>
```{r eval=FALSE}
dir.path = "C:/Users/henni/Dropbox/ss3diags_demo/PacificHake"
ss3pke = r4ss::SS_output(file.path(dir.path,"Reference_Run"))
```
<br>

- `retro.phk`: list of retrospective runs with `r4ss:SS_doRetro()` as read by `r4ss::SSgetoutput()`
<br>


In this case the retrospective runs, produced with `r4ss:SS_doRetro()`(see recipe below), were located in the subfolders `/Retro_Reference_Run` and named "retro0","retro-1", "retro-2" and so on. To load those at once we use the `r4ss::SSgetoutput()`. In this case we conducted eight retrospective runs, where "retro0" corresponds to the "Reference_Run" and "retro-1" to "retro-7" are "peels". To assign the model names, we there specify `start.retro = 0` and `end.retro = 7` below.     
<br>


```{r eval=FALSE}
start.retro = 0
end.retro = 7
retro.runs = "Retro_Reference_Run"
# load models
retro.phk <- r4ss::SSgetoutput(dirvec=file.path(dir.path,
retro.runs,paste0("retro",start.retro:-end.retro)))

```
<br>
Again, note that list object `retro.phk[[1]]` ("retro0") corresponds to the reference run ss3phk 
<br><br>

`aspm.phk`: Comprises of two runs the "Reference_Run" and the "ASPM", which can be loaded together using `r4ss::SSgetoutput()` and then summarized with `r4ss::SSsummarize()` 

<br>

```{r eval=FALSE}
asem.phk <- r4ss::SSgetoutput(dirvec=
                        file.path(dir.path,paste0("Reference_Run","APSM")))
asem.phk <- r4ss::SSsummarize(asem.phk)
```
<br>

### The ICCAT North Atlantic shortfin mako (*Isurus oxyrinchus*) reference model

```{r}
data("natl.sma")
```
<br>
Individual list objects generated using R package [r4ss](https://github.com/r4ss/r4ss):
<br>

- `ss3sma`:  output from Stock Synthesis as read by `r4ss::SS_output()` 

- `retro.sma`: list of retrospective runs with `r4ss:SS_doRetro()` as read by `r4ss::SSgetoutput()`

- `aspm.sma`: list of Stock Synthesis referece and aspm created with `r4ss::SSsummarize()`

<br>

# Model Diagnostics with ss3diags 

## Plotting residual diagnostic with `ss3diags` 

The plotting options are kept mostly to those provided by [r4ss](https://github.com/r4ss/r4ss).
Just like with [r4ss](https://github.com/r4ss/r4ss), if, for example, `SSplotRunstest() called with no further specifications several windows will open,  which depends in this case on the number abundance indices.

<br>

```{r eval=FALSE}
SSplotRunstest(ss3sma)
```

<br>

The runs test is a nonparametric hypothesis test for
randomness in a data sequence that calculates the 2-sided p-value to
estimate the number of runs (i.e., sequences of values of the same sign)
above and below a reference value. the runs test can diagnose model misspecification using residuals from fits to abundance indices [(Carvalho et al. 2017)](https://www.sciencedirect.com/science/article/pii/S0165783616303113). It can also be applied to other data components in assessment models such as the mean-length residuals and mean-age residuals. In addition, the three-sigma limits can be considered
to identify potential outliers as any data point would be unlikely given a random process error in the observed residual distribution if it is further than three
standard deviations away from the expected residual process average of
zero.


To visiualized the runs test for multiple indices, it is suggested to make use of the function `sspar()` and the option plot `add=TRUE`. `sspar()` facilitates setting the graphic parameters so that they are suitable for `ss3diags` plots and option `add=TRUE` prevents the plotting functions from over-writing `sspar()`.

<br>

```{r fig1, fig.height=6, fig.cap = "Runs test plots for CPUE index fits. Green shading indicates no evidence (p ≥ 0.05) and red shading evidence (p < 0.05) to reject the hypothesis of a randomly distributed time-series of residuals, respectively. The shaded (green/red) area spans three residual standard deviations to either side from zero, and the red points outside of the shading violate the ‘three-sigma limit’ for that series."}

sspar(mfrow=c(3,2),plot.cex=0.8)
rt = SSplotRunstest(ss3sma,add=T,verbose=F)
```
<br><br>

It is also possible to select the indices that should be plotted. For example, in this case we may want to exclude CPUE2 as it was not fitted (zero weight to the likelihood). This also creates space to add another plot, such as joint-residual `SSplotJABBAres` to summarize all selected indices.

<br><br>

```{r fig2,fig.height=6, fig.cap="Runs test plot and Joint residual plot for fits to CPUE indices, where the vertical lines with points show the residuals, and solid black lines show loess smoother through all residuals. Boxplots indicate the median and quantiles in cases where residuals from the multiple indices are available for any given year. Root-mean squared errors (RMSE) are included in the upper right-hand corner of each plot."}

sspar(mfrow=c(3,2),plot.cex=0.8)
rt= SSplotRunstest(ss3sma,add=T,indexselect = c(1,3:6),legendcex = 0.8,verbose=F)
jr = SSplotJABBAres(ss3sma,add=T,indexselect = c(1,3:6),legendcex = 0.55,verbose=F)
```

<br><br>


The default for `SSplotRunstest()` and `SSplotJABBAres()` is plot the residual runs for the abundance indices, but it is also possible to do the plot plot for the composition data by specifying `subplots="len"` (or "age")
<br><br>

```{r fig3, fig.height=6,fig.cap= "Runs test plot and Joint residual plot for mean lengths from fits length composition data"}
sspar(mfrow=c(3,2),plot.cex=0.8)
rt= SSplotRunstest(ss3sma,add=T,legendcex = 0.8,subplot="len",verbose=F)
jr = SSplotJABBAres(ss3sma,add=T,
                  legendcex = 0.55,legendloc="bottomright",subplot="len",verbose=F)
```


<br> <br>

\newpage

Several diagnostic tests can also be called without plotting, e.g. to facilitate automated processing  

<br> 

```{r}
rti= SSrunstest(ss3sma,quant="cpue",verbose=F)
rtl= SSrunstest(ss3sma,quant="len",verbose=F)
rbind(rti,rtl)
```
<br><br>
The pacific hake assessment provides an example of fits to age composition instead of length composition data, which can plotted by specifying `subplots="age"`
<br><br>

```{r,fig.height=4, fig.cap="Runs test plot and Joint residual plot for a survey abudance index and mean ages from fits to survey and fisheries dependent age-composition data"}

sspar(mfrow=c(2,2),plot.cex=0.8)
rti = SSplotRunstest(ss3phk,add=T,legendcex = 0.8,subplot="cpue",verbose=F)
rta = SSplotRunstest(ss3phk,add=T,legendcex = 0.8,subplot="age",verbose=F)
jra = SSplotJABBAres(ss3phk,add=T,legendcex = 0.7,subplot="age",verbose=F)
```

<br> 

<br> 


## Ploting Retrospective and Forecast bias

Retrospective analysis is commonly used to check the consistency of model estimates, i.e., the invariance in spawning stock biomass (SSB) and fishing mortality (F) as the model is
updated with new data in retrospect. The retrospective analysis involves sequentially removing observations from the terminal year (i.e., peels), fitting the model to the truncated series, and then comparing the relative difference between model estimates from the full-time series with the truncated time-series.

In Stock Synthesis, retrospective analysis can be routinely implemented in Stock Synthesis using `r4ss:SS_doRetro()` available in [r4ss](https://github.com/r4ss/r4ss) as demonstrated in Section [3.1][Retrospetive with hindcasts]. `ss3diags` then provides the function `SSplotRetro()` to visualize the retrospective patterns of SBB and F and to compute the associated Mohn's rho value (i.e. retrospective bias). This would require to first load the retrospective runs (Section [1.2][Loading built-in example data]), which are already inbuilt into `ss3diags` in this case. The next step is summarize the list of retrospective runs using `r4ss::SSsummarize()`.


```{r}
retroI.phk <- r4ss::SSsummarize(retro.phk,verbose=F)
```

We use notation "retroI" because `r4ss::SSsummarize()` summarizes the modelled quantaties and abudances indices, but length or age composition data, which becomes relevant again in the next Section. With summarized object `retroI.phk` it is now possible to produce some basic retrospective plots.

```{r fig5, fig.height=3,fig.cap= "Retrospective analysis of spawning stock biomass (SSB) and fishing mortality estimates for Pacific hake conducted by re-fitting the reference model (Ref) after seven years, one year at a time sequentially. Mohn’s rho statistic are denoted on top of the panels. Grey shaded areas are the 95 \\% confidence intervals from the reference model in cases where the analysis was run with Hessiean"}

sspar(mfrow=c(1,2),plot.cex=0.8)
rb = SSplotRetro(retroI.phk,add=T,forecast = F,legend = F,verbose=F)
rf = SSplotRetro(retroI.phk,add=T,subplots="F", ylim=c(0,0.4),
                 forecast = F,legendloc="topleft",legendcex = 0.8,verbose=F)

```



Retrospective analysis is useful to evaluate how consistent the modeled
quantities are in retrospect. However, providing fisheries management
advice requires predicting a stock’s response to management and
checking that predictions are consistent when updated by new data in the future.  A first, intuitive extension of the retrospective analysis is to assess potential forecast bias by adding the additional step of forward projecting quantities, such as SSB, over the truncated years. A desirable feature of Stock Synthesis is that forecasts are automatically done when using `r4ss:SS_doRetro()`.The forecasts are based on the settings in ‘forecast.ss’, which are also evoked when conducting future projections with the same model, only that the observed catches are used for the retrospective forecasts. Retrospective forecasts (i.e. hindcasts) with Stock Synthesis is therefore only a matter of visualization, which can be done by setting the `SSplotRetro()` option `forecast=TRUE`.


```{r fig6, fig.height=3.,fig.cap= "Retrospective results shown for the most recent years only. Mohn’s rho statistic and the corresponding ‘hindcast rho’ values (in brackets) are now printed at the top of the panels. One-year-ahead projections denoted by color-coded dashed lines with terminal points are shown for each model."}

sspar(mfrow=c(1,2),plot.cex=0.8)
rb = SSplotRetro(retroI.phk,add=T,forecast = T,legend = F,verbose=F,xmin=2000)
rf = SSplotRetro(retroI.phk,add=T,subplots="F", ylim=c(0,0.4),
                forecast = T,legendloc="topleft",legendcex = 0.8,verbose=F,xmin=2000)

```


\newpage

The statistics in from the retrospective analysis with forecasting, including mohn's rho and forecast bias, can also be called without plotting using the function `SShcbias()`   

<br><br>  

```{r}
SShcbias(retroI.phk,quant="SSB",verbose=F)

SShcbias(retroI.phk,quant="F",verbose=F)

```

<br> <br> <br> 

## Hindcast Cross-Validation and prediction skill 

Retrospective forecasting provides an indication of the expected bias of in modelled quantities when updated with new data, but is not suitable for model validation, which should based on actual observations that are unknown to the model.To address this, [Kell et al. (2016)](https://www.sciencedirect.com/science/article/abs/pii/S0165783616301540) proposed the used of hindcasting  cross-validation techniques (HCXval) for stock assessment model validation, where observations (e.g. CPUE, length comps) are compared to their predicted future values. The key concept behind the HCXval approach is ’prediction skill’, which is defined as any measure of the accuracy of a forecasted value to the actual observed value that is not known by the model (Kell et al., 2021).

<br> 
Implementing the Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis  requires the same model outputs that are already produced with generated by `r4ss:SS_doRetro()` as described in Section [3.1][Retrospetive with hindcasts]. Therefore, there is no additional computationally intensive step needed for HCxval if conducted in conjunction with retrospective analysis. 
<br> 
As robust measure of prediction skill, we implemented the mean absolute
scaled error (MASE). In brief, the MASE score scales
the mean absolute error (MAE) of forecasts (i.e., prediction residuals) to
MAE of a naïve in-sample prediction, which is realized in the form of a simple 'persistence algorithm', i.e. tomorrow’s weather will be the same as today’s (see Eq. 3, p.5 in [Carvalho and Winker et al. 2021](https://www.sciencedirect.com/science/article/pii/S0165783621000874)). A MASE score > 1 indicates that the average model forecasts are worse than a random walk. Conversely, a MASE score of 0.5 indicates that the model forecasts twice as accurately as a naïve baseline prediction; thus, the model has prediction skill.

<br> 
HCxval is implemented for Stock Synthesis using function `SSplotHCxval()`to produce the novel HCxval diagnostic plot and computes the MASE scores for CPUE indices, mean lengths or mean ages that have observations falling within the hindcast evaluation period.
<br> 

Plotting HCxval for abudance indices requires the same step of summarizing the list of retrospective runs as for the retrospective analysis, which, of course, only needs be done once. Here, we summarize the retro runs for shortfin mako.


```{r eval=TRUE}
retroI.sma <- r4ss::SSsummarize(retro.sma,verbose=F)
```


```{r fig7, fig.height=5.5,fig.cap= "Hindcasting cross-validation (HCxval) results CPUE fits, showing observed (large points connected with dashed line), fitted (solid lines) and one-yearahead forecast values (small terminal points).HCxval was performed using one reference model (Ref) and five hindcast model runs (solid lines) relative to the expected CPUE. The observations used for crossvalidation are highlighted as color-coded solid circles with associated 95 \\% confidence intervals. The model reference year refers to the endpoints of each one-year-ahead forecast and the corresponding observation (i.e., year of peel + 1). The mean absolute scaled error (MASE) score associated with each CPUE"}

sspar(mfrow=c(3,2),plot.cex=0.8)
hci = SSplotHCxval(retroI.sma,add=T,verbose=F,ylimAdj = 1.3,legendcex = 0.7)
```

\newpage

By comparison, the forecast length- and age-composition are somewhat hidden as "ghost files" of Stock Synthesis report.sso. To extract and summarize the composition in the form of oberved and expected mean lenghts and mean ages, respectively, `ss3diags` provides the function `SSretroComps()`.

```{r}
retroC.sma = SSretroComps(retro.sma)
```

```{r fig8, fig.height=3,fig.cap= "Hindcasting cross-validation (HCxval) results for mean lengths. Note that MASE values in breakets are adjusted MASE values for cases where naive predictions have a Mean-Absolute-Error below 0.1"}

sspar(mfrow=c(1,2),plot.cex=0.8)
hcl = SSplotHCxval(retroC.sma,subplots="len",add=T,verbose=F,
ylimAdj = 1.3,legendcex = 0.7,indexselect = c(1,2))
```

Note that Figure 8, provides some additional, so called adjusted MASE values, in brackets. This gets invoked in cases where the inter-annual variation in the observed values is very small (default MAE < 0.1 for naive predictions log(y[t+1])-log(y[t])).
The reasoning is that prediction residuals must be already very accurate to fall below this threshold. The adjusted MASE essential keep the naive prediction MAE denominator of the MASE to a maximum. Below we show the effect of changing adjustment threshold from the default `MAE.base.adj = 0.1`


```{r}
mase1 = SSmase(retroC.sma,quant="len",MAE.base.adj = 0.1,indexselect = c(1:2))
mase1
```

to a larger value `MAE.base.adj = 0.15`

```{r}
SSmase(retroC.sma,quant="len",MAE.base.adj = 0.15,indexselect = c(1:2))
```

where `MASE` is the ratio of the mean absolute error of the prediction residuals `MAE.PR` to the residuals of the naive predictions `MAE.base`

```{r}
mase1$MAE.PR/mase1$MAE.base
mase1$MASE
```

and MASE.adj


```{r}
mase1$MAE.PR/pmax(mase1$MAE.base,0.1)
mase1$MASE.adj
```

Note that applying HCxval for composition data requires to correctly specify the composition data type that was fitted in the model. For example, age composition data need be specified as "age" in `SSplotHCxval` and `SSmase`, as shown below for the Pacific hake model.

```{r fig9, fig.height=3,fig.cap= "Hindcasting cross-validation (HCxval) results for mean lengths. Note that MASE values in breakets are adjusted MASE values for cases where naive predictions have a Mean-Absolute-Error below 0.1"}

retroC.phk = SSretroComps(retro.phk) # summarize comps

sspar(mfrow=c(1,2),plot.cex=0.8)
hcl = SSplotHCxval(retroC.phk,subplots="age",add=T,
verbose=F,ylimAdj = 1.3,legendcex = 0.7,indexselect = c(1,2))

SSmase(retroC.phk,quants="age")
```



\newpage

## Uncertainty with `ss3diags` 

The management advice frameworks increasingly require translating the estimated uncertainty about the stock status into probabilistic statements (Kell et al. 2016). A classical example is the Kobe framework that is use in tuna Regional Fisheries Management Organisations around the world. The key quantities of interest are typically the ratios $SSB/SSB_{MSY}$ and $F/F_{MSY}$. While is reasonably straight forward in Stock Synthesis to approximate uncertainty of individual quantities (e.g. $SSB$) from the asymptotic standard errors (SE) derived from the hessian matrix using the delta method, the joint distribution of $SSB/SSB_{MSY}$ and $F/F_{MSY}$   
requires to adequately account for the covariance structure between these two derived quantities. Joint distributions were therefore typical constructed using bootstrap or Markov Chain Monte-Carlo (MCMC) methods. However, these methods can be computationally intense and time consuming in integrated assessments.  

As an alternative, `ss3diags` implements a rapid delta-Multivariate lognormal approximation with `SSdeltaMVLN()` to generate joint error distributions for $SSB/SSB_{ref}$ and $F/F_{ref}$,where the $ref$ may refer to $MSY$, but also, e.g., $SSB_{40}$ and $F_{40}$. In Stock Synthesis, these ratios are determined by the derived quantaties  `Bratio` and `F`, where either can take the form of ratios (e.g. $F/F_{ref}$) or absolute value (e.g. `absF`) depending on settings in the `starter.ss` file.

Let `Bratio` be $u = SSB/SSB_{ref}$, `F` be $v = F$, and $w = F_{ref}$ be the F reference point of interest (e.g. $F_{MSY}$), with $x = \log(u)$, $y = \log(v)$ and $z = \log(w)$, then the variance-covariance matrix $VCM$ has the form:

$$
VCM_{x,y,z} =
 \begin{pmatrix}
  \sigma^2_{x} & cov_{x,y} & cov_{x,y} \\
  cov_{x,y} & \sigma^2_{y} & cov_{y,z} \\
  cov_{x,z} & cov_{y,z} & \sigma^2_{z}
 \end{pmatrix}
$$

where, e.g., $\sigma^2_{x}$ is the variance of $x$ and $cov_{x,y}$ is the covariance of $x$ and $y$. Deriving those requires to conduct a few normal to lognormal transformations. First, we approximate the variances as:

$$
\sigma^2_{x} = \log\left(1+\left(\frac{SE_u}{u}\right)^2\right)  
$$
$$
\sigma^2_{y} = \log\left(1+\left(\frac{SE_u}{u}\right)^2\right)  
$$

$$
\sigma^2_{z} = \log\left(1+\left(\frac{SE_w}{w}\right)^2\right)  
$$



where $SE_{u}$, $SE_{v}$ and $SE_{z}$ are the asymptotic standard error estimates for $u = SSB/SSB_{ref}$, $v = F$ and $z = F_{ref}$. 

The covariances for, e.g.  x and y, can then be approximated on the log-scale by:

$$
COV_{x,y} = \log \left( {1+\rho_{u,v} \sqrt{\sigma^2_{x}\sigma^2_{y}}} \right) 
$$

where $rho_{u,v}$ denotes the correlation of u and v.

To generate a joint distribution of $\tilde{u}$ = $SSB/SSB_{ref}$, $\tilde{v}$ = $F$ and $\tilde{z}$ = $F_{ref}$, we use a multivariate random generator, available in the R package ‘mvtnorm’, to obtain a large number (e.g. nsim = 10,000) iterations, such that

$$
JD(\tilde{u},\tilde{v},\tilde{w}) = \exp(MVN(\mu_{x,y,z},VCM_{x,y,z}))
$$
so that

$$ 
\tilde{SSB}/\tilde{SSB}_{{MSY}} = \tilde{u}  
$$ 
and

$$ 
\tilde{F}/\tilde{F}_{{MSY}} = \tilde{v}/\tilde{w}  
$$ 
 
 

 
The type of reference points dependents on settings in the `starter.ss` file that determine the derived quanties `Bratio` and `Fvalue`. `SSdeltaMVLN()` has been tested thus for the settings for `Bratio`:

`1 or 2# Depletion basis:  denom is: 0=skip; 1=rel X*SPB0; 2=rel SPBmsy; 3=rel X*SPB_styr; 4=rel X*SPB_endyr`

 


## Model Ensembles with `ss3diags`



# Cookbook Recipies

## Retrospetive with hindcasts

Retrospective analysis can be run for Stock Synthesis using the function `r4ss::SS_doRetro()` available in [r4ss](https://github.com/r4ss/r4ss). This setup of the retrospective analysis has the advantage that forecasts are conducted automatically given the catch. This makes in possible to apply retrospective forecasting and hindcast cross-validations of observations based on the same output.

```{r eval=TRUE}
library(r4ss)
```
In the following we provide a step-by-step cookbook recipe for retrospective analysis in Stock Synthesis.


### Identify restrospective period



The first step is specifying the range pf peels that will then determine the  `end.yr.vec` of runs in `r4ss::SS_doRetro()`

```{r eval=TRUE}
start.retro <- 0    # end year of reference year
end.retro   <- 7    # number of years for retrospective e.g., 
```

### Identify the base directory

The second step is to specify the path directory that holds the folder with the base case run. In this case the Pacific Hake folder with a model folder `Reference_Run" 

<br>

```{r eval=F}
dirname.base = "C:/Users/henni/Dropbox/ss3diags_demo/PacificHake"
run = "Reference_Run" 

model.run <- file.path(dirname.base,run)

model.run

```
<br>
### DAT and CONTROL files

The third step is to specify the names of the data and control files.
Note these files are named differently from the `DATA.ss` and `CONTROL.ss`. In this case  
<br>

```{r eval=F}
DAT = "phk.dat"
CTL =  "phk.ctl"
```
<br>
The names of the DAT and CONTROL are declared on the top of the 'starter.ss`, e.g.

`#C Hake starter file`
`phk.dat`
`phk.ctl`

<br>

### Create a subdirectory for the Retrospectives

There are several ways to organise the retrospective output sturcture.
Here we simpy create a new subfolder for the retrospective runs output
<br>
```{r eval=FALSE}
dir.retro <- paste0(dirname.base,'/Retro_',run)

dir.create(path=dir.retro, showWarnings = F)

```

We also create a subdirectory for the retrospective model folders 

```{r eval=FALSE}

dir.create(path=file.path(dirname.Retrospective,"retros"), showWarnings = F)
```
<br>


### Copy model run files to new retrospective folder
<br>
```{r eval=FALSE}
file.copy(file.path(model.run,"starter.ss_new"),  file.path(dir.retro,"starter.ss"))

file.copy(file.path(model.run,"control.ss_new"),
file.path(dir.retro, CTL))

file.copy(file.path(model.run,"data.ss_new"),
file.path(dir.retro, DAT))	

file.copy(file.path(model.run,"forecast.ss"),
file.path(dir.retro, "forecast.ss"))

file.copy(file.path(model.run,"SS.exe"),
file.path(dir.retro, "SS.exe"))

# Automatically ignored for models without wtatage.ss 
file.copy(file.path(model.run,"wtatage.ss"),
file.path(dir.retro, "wtatage.ss"))
```


### Modify Starter.ss file 

Modifying the Starter File helps to speed up model runs
<br>
```{r eval=FALSE}
starter <- readLines(paste0(dir.retro, "/starter.ss"))

#[8] "2 # run display detail (0,1,2)" 
linen <- grep("# run display detail", starter)
starter[linen] <- paste0( 1 , " # run display detail (0,1,2)" )
# write modified starter.ss
write(starter, file.path(dir.retro, "starter.ss"))
```
<br>
### Execute retrospective runs  

Now all is readt to run the retrospective analyses with r4SS function ` SS_doRetro`
<br>
Ideally, the runs should be done with Hessian to allow evaluating the retrospective trajectories with respect to confidence interval coverage of the reference model.
<br>
```{r eval=FALSE}
r4ss::SS_doRetro(masterdir=dir.retro, oldsubdir="",
newsubdir="", years=start.retro:-end.retro)
```
<br>
However, for larger models it might be desirable to shorten run times, by not inverting the hessian, using the option `extras = "-nohess"` (much faster)   
<br>
```{r eval=FALSE}
r4ss::SS_doRetro(masterdir=dir.retro,oldsubdir="",
newsubdir="", years=start.retro:-end.retro,extras = "-nohess")
```
<br>

### Read `SS_doRetro()` output
<br>
```{r eval=FALSE}
retro.phk <- r4ss::SSgetoutput(dirvec=file.path(dir.retro,
              paste0("retro",start.retro:-end.retro)))
```
<br>
It is often useful to save the retro model runs as `.rdata` file for further processing with `ss3diags`, considering that reading the models with `r4ss::SSgetoutput()` can be quite time-consuming for more complex models. 

<br>

```{r eval=FALSE}
save(retro.phk, file=file.path(dir.retro,"retro.phk.rdata"))
```

### Quick Check


```{r eval=T}
library(ss3diags)

check.retro =r4ss::SSsummarize(retro.phk)
sspar(mfrow=c(1,1))
SSplotRetro(check.retro,forecast = T,add=T,legendcex = 0.7,legendloc = "topleft")

```


## Profiling

## Jittering

